#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ Excel –æ—Ç—á–µ—Ç–æ–≤ Cian –≤ —Ñ–æ—Ä–º–∞—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø–æ–ª–Ω—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
"""

import sqlite3
import os
import random
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import json

logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å pandas –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
    logger.info("‚úÖ Pandas –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel")
except ImportError:
    PANDAS_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Pandas –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pandas openpyxl")

class CianReportDBConverter:
    """–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä Excel –æ—Ç—á–µ—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, excel_file_path: str = "dataBD/cian_report.xlsx"):
        self.excel_file_path = excel_file_path
        self.output_db_path = "dataBD/cian_reports.db"
        self.random_data_generators = self._setup_random_generators()
    
    def _setup_random_generators(self) -> Dict:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return {
            'addresses': [
                '–≥. –ü–µ—Ä–º—å, —É–ª. –õ–µ–Ω–∏–Ω–∞, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ú–∏—Ä–∞, {}', 
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ö–æ–º—Å–æ–º–æ–ª—å—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ü–µ—Ç—Ä–æ–ø–∞–≤–ª–æ–≤—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –†–µ–≤–æ–ª—é—Ü–∏–∏, {}',
                '–≥. –ü–µ—Ä–º—å, –ø—Ä–æ—Å–ø–µ–∫—Ç –ü–∞—Ä–∫–æ–≤—ã–π, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ö—É–π–±—ã—à–µ–≤–∞, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –°–∏–±–∏—Ä—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ï–∫–∞—Ç–µ—Ä–∏–Ω–∏–Ω—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ì–∞–∑–µ—Ç—ã –ó–≤–µ–∑–¥–∞, {}'
            ],
            'property_types': [
                '–û—Ñ–∏—Å', '–¢–æ—Ä–≥–æ–≤–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ', '–°–∫–ª–∞–¥—Å–∫–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ', 
                '–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ', '–°–≤–æ–±–æ–¥–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ',
                '–û–±—â–µ–ø–∏—Ç', '–ê–≤—Ç–æ—Å–µ—Ä–≤–∏—Å', '–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ü–µ–Ω—Ç—Ä',
                '–°–∞–ª–æ–Ω –∫—Ä–∞—Å–æ—Ç—ã', '–ê–≤—Ç–æ–º–æ–π–∫–∞'
            ],
            'descriptions': [
                '–û—Ç–ª–∏—á–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º –≤—Ö–æ–¥–æ–º',
                '–ü—Ä–æ—Å—Ç–æ—Ä–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ —Å –≤—ã—Å–æ–∫–∏–º–∏ –ø–æ—Ç–æ–ª–∫–∞–º–∏',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ö–æ–¥–Ω–æ–º –º–µ—Å—Ç–µ',
                '–£–¥–æ–±–Ω–∞—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∞',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –ø–∞—Ä–∫–æ–≤–∫–æ–π',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ –≤ –¥–µ–ª–æ–≤–æ–º —Ü–µ–Ω—Ç—Ä–µ',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –æ—Ç–ª–∏—á–Ω–æ–π –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å—é',
                '–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ'
            ],
            'contact_phones': [
                '+7(342)123-45-67', '+7(342)234-56-78', '+7(342)345-67-89',
                '+7(342)456-78-90', '+7(342)567-89-01', '+7(342)678-90-12',
                '+7(342)789-01-23', '+7(342)890-12-34', '+7(342)901-23-45',
                '+7(342)012-34-56'
            ],
            'areas': [15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300, 400, 500],
            'floors': ['1/5', '2/5', '3/5', '1/9', '2/9', '3/9', '4/9', '5/9', '1/12', '2/12', '3/12'],
            'prices': [30000, 35000, 40000, 45000, 50000, 60000, 70000, 80000, 90000, 100000, 120000, 150000, 200000]
        }
    
    def read_excel_report(self) -> Optional[pd.DataFrame]:
        """–ß–∏—Ç–∞–µ—Ç Excel —Ñ–∞–π–ª –æ—Ç—á–µ—Ç–∞"""
        if not PANDAS_AVAILABLE:
            logger.error("Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: pip install pandas openpyxl")
            return None
            
        try:
            if not os.path.exists(self.excel_file_path):
                logger.error(f"–§–∞–π–ª {self.excel_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —á—Ç–µ–Ω–∏—è Excel
            try:
                df = pd.read_excel(self.excel_file_path)
                logger.info(f"‚úÖ Excel —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} —Å—Ç—Ä–æ–∫")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞
                if len(df.columns) == 2 and any('–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å' in str(col).lower() for col in df.columns):
                    logger.info("üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è...")
                    return self._generate_listings_from_stats(df)
                
                return df
            except Exception as e:
                # –ü—Ä–æ–±—É–µ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º engine
                df = pd.read_excel(self.excel_file_path, engine='openpyxl')
                logger.info(f"‚úÖ Excel —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω (openpyxl): {len(df)} —Å—Ç—Ä–æ–∫")
                return df
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è Excel —Ñ–∞–π–ª–∞: {e}")
            return None
    
    def _generate_listings_from_stats(self, stats_df: pd.DataFrame) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –æ—Ç—á–µ—Ç–∞"""
        logger.info("üèóÔ∏è –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        listings_count = 5  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        try:
            for _, row in stats_df.iterrows():
                if '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ' in str(row.iloc[0]).lower() and '–æ–±—ä—è–≤–ª–µ–Ω–∏–π' in str(row.iloc[0]).lower():
                    try:
                        listings_count = int(row.iloc[1])
                        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ: {listings_count} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                        break
                    except:
                        pass
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        generated_listings = []
        
        for i in range(max(listings_count, 1)):  # –º–∏–Ω–∏–º—É–º 1 –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
            listing = {
                'id': f"generated_{random.randint(100000, 999999)}",
                'source': 'cian',
                'price': random.choice(self.random_data_generators['prices']),
                'area': f"{random.choice(self.random_data_generators['areas'])} –º¬≤",
                'description': random.choice(self.random_data_generators['descriptions']),
                'url': f"https://perm.cian.ru/rent/commercial/{random.randint(100000, 999999)}/",
                'floor': random.choice(self.random_data_generators['floors']),
                'address': random.choice(self.random_data_generators['addresses']).format(random.randint(1, 200)),
                'lat': round(58.0 + random.uniform(-0.1, 0.1), 6),
                'lng': round(56.25 + random.uniform(-0.1, 0.1), 6),
                'seller': random.choice(self.random_data_generators['contact_phones']),
                'photos': json.dumps([]),
                'status': random.choice(['open', 'active', 'available']),
                'visible': 1
            }
            generated_listings.append(listing)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        df = pd.DataFrame(generated_listings)
        logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        return df
    
    def generate_random_value(self, field_name: str, existing_value: Any = None) -> Any:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—è"""
        if existing_value and pd.notna(existing_value) and str(existing_value).strip():
            return existing_value
        
        field_name_lower = field_name.lower()
        
        if 'price' in field_name_lower or '—Ü–µ–Ω–∞' in field_name_lower:
            return random.choice(self.random_data_generators['prices'])
        
        elif 'area' in field_name_lower or '–ø–ª–æ—â–∞–¥—å' in field_name_lower:
            return random.choice(self.random_data_generators['areas'])
        
        elif 'address' in field_name_lower or '–∞–¥—Ä–µ—Å' in field_name_lower:
            template = random.choice(self.random_data_generators['addresses'])
            return template.format(random.randint(1, 200))
        
        elif 'type' in field_name_lower or '—Ç–∏–ø' in field_name_lower:
            return random.choice(self.random_data_generators['property_types'])
        
        elif 'floor' in field_name_lower or '—ç—Ç–∞–∂' in field_name_lower:
            return random.choice(self.random_data_generators['floors'])
        
        elif 'phone' in field_name_lower or '—Ç–µ–ª–µ—Ñ–æ–Ω' in field_name_lower:
            return random.choice(self.random_data_generators['contact_phones'])
        
        elif 'description' in field_name_lower or '–æ–ø–∏—Å–∞–Ω–∏–µ' in field_name_lower:
            return random.choice(self.random_data_generators['descriptions'])
        
        elif 'url' in field_name_lower or '—Å—Å—ã–ª–∫–∞' in field_name_lower:
            return f"https://perm.cian.ru/rent/commercial/{random.randint(100000, 999999)}/"
        
        elif 'id' in field_name_lower:
            return random.randint(100000, 999999)
        
        elif 'source' in field_name_lower or '–∏—Å—Ç–æ—á–Ω–∏–∫' in field_name_lower:
            return 'cian'
        
        elif 'status' in field_name_lower or '—Å—Ç–∞—Ç—É—Å' in field_name_lower:
            return random.choice(['open', 'active', 'available'])
        
        elif 'visible' in field_name_lower:
            return 1
        
        elif 'lat' in field_name_lower or 'latitude' in field_name_lower:
            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ü–µ—Ä–º–∏
            return round(58.0 + random.uniform(-0.1, 0.1), 6)
        
        elif 'lng' in field_name_lower or 'longitude' in field_name_lower:
            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –ü–µ—Ä–º–∏  
            return round(56.25 + random.uniform(-0.1, 0.1), 6)
        
        elif 'date' in field_name_lower or '–≤—Ä–µ–º—è' in field_name_lower:
            # –°–ª—É—á–∞–π–Ω–∞—è –¥–∞—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
            days_ago = random.randint(0, 30)
            return (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m-%d %H:%M:%S')
        
        else:
            # –û–±—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return f"–ê–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–æ_{random.randint(1000, 9999)}"
    
    def normalize_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç DataFrame –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É –ë–î"""
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ë–î –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        standard_columns = {
            'id': 'id',
            'source': 'source', 
            'price': 'price',
            'area': 'area',
            'description': 'description',
            'url': 'url',
            'floor': 'floor',
            'address': 'address',
            'lat': 'lat',
            'lng': 'lng',
            'seller': 'seller',
            'photos': 'photos',
            'status': 'status',
            'visible': 'visible'
        }
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        normalized_df = pd.DataFrame()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –º–∞–ø–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
        for std_col, _ in standard_columns.items():
            found_column = None
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            for col in df.columns:
                col_lower = str(col).lower()
                if (std_col.lower() in col_lower or 
                    (std_col == 'price' and ('—Ü–µ–Ω–∞' in col_lower or '—Å—Ç–æ–∏–º–æ—Å—Ç—å' in col_lower)) or
                    (std_col == 'area' and ('–ø–ª–æ—â–∞–¥—å' in col_lower or '–∫–≤' in col_lower)) or
                    (std_col == 'address' and ('–∞–¥—Ä–µ—Å' in col_lower or '—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ' in col_lower)) or
                    (std_col == 'description' and ('–æ–ø–∏—Å–∞–Ω–∏–µ' in col_lower or '–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π' in col_lower))):
                    found_column = col
                    break
            
            if found_column:
                normalized_df[std_col] = df[found_column]
                logger.info(f"‚úÖ –ú–∞–ø–∏–Ω–≥: {found_column} -> {std_col}")
            else:
                # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
                normalized_df[std_col] = None
                logger.info(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ {std_col} –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        
        return normalized_df
    
    def fill_missing_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ó–∞–ø–æ–ª–Ω—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏"""
        logger.info("üé≤ –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ...")
        
        filled_df = df.copy()
        
        for column in filled_df.columns:
            missing_count = filled_df[column].isna().sum()
            if missing_count > 0:
                logger.info(f"–ó–∞–ø–æ–ª–Ω—è–µ–º {missing_count} –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–µ '{column}'")
                
                for idx in filled_df[filled_df[column].isna()].index:
                    filled_df.at[idx, column] = self.generate_random_value(column)
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è photos (JSON –º–∞—Å—Å–∏–≤)
        if 'photos' in filled_df.columns:
            filled_df['photos'] = filled_df['photos'].apply(
                lambda x: json.dumps([]) if pd.isna(x) else x
            )
        
        logger.info("‚úÖ –í—Å–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")
        return filled_df
    
    def create_database_schema(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ö–µ–º—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(os.path.dirname(self.output_db_path), exist_ok=True)
            
            with sqlite3.connect(self.output_db_path) as conn:
                cursor = conn.cursor()
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS cian_reports (
                        id TEXT PRIMARY KEY,
                        source TEXT NOT NULL DEFAULT 'cian',
                        price REAL,
                        area TEXT,
                        description TEXT,
                        url TEXT,
                        floor TEXT,
                        address TEXT,
                        lat TEXT,
                        lng TEXT,
                        seller TEXT,
                        photos TEXT DEFAULT '[]',
                        status TEXT DEFAULT 'open',
                        visible INTEGER DEFAULT 1,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_reports_price ON cian_reports(price)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_reports_area ON cian_reports(area)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_reports_status ON cian_reports(status)")
                
                conn.commit()
                logger.info(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω–∞: {self.output_db_path}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î: {e}")
            raise
    
    def save_to_database(self, df: pd.DataFrame) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.create_database_schema()
            
            with sqlite3.connect(self.output_db_path) as conn:
                # –û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                conn.execute("DELETE FROM cian_reports")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                df.to_sql('cian_reports', conn, if_exists='append', index=False)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM cian_reports")
                count = cursor.fetchone()[0]
                
                logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
                return True
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
            return False
    
    def convert_excel_to_db(self) -> bool:
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ Excel –≤ –ë–î"""
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é Excel –æ—Ç—á–µ—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        
        # –®–∞–≥ 1: –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
        df = self.read_excel_report()
        if df is None:
            return False
        
        logger.info(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        logger.info(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –®–∞–≥ 2: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        normalized_df = self.normalize_dataframe(df)
        
        # –®–∞–≥ 3: –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        filled_df = self.fill_missing_data(normalized_df)
        
        # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        success = self.save_to_database(filled_df)
        
        if success:
            logger.info(f"üéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            logger.info(f"üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.output_db_path}")
            return True
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
            return False
    
    def get_database_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –ë–î"""
        try:
            with sqlite3.connect(self.output_db_path) as conn:
                cursor = conn.cursor()
                
                # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                cursor.execute("SELECT COUNT(*) FROM cian_reports")
                total_count = cursor.fetchone()[0]
                
                # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞
                cursor.execute("SELECT AVG(price) FROM cian_reports WHERE price > 0")
                avg_price = cursor.fetchone()[0] or 0
                
                # –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω
                cursor.execute("SELECT MIN(price), MAX(price) FROM cian_reports WHERE price > 0")
                min_price, max_price = cursor.fetchone()
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ —Ç–∏–ø–∞–º —Å—Ç–∞—Ç—É—Å–∞
                cursor.execute("SELECT status, COUNT(*) FROM cian_reports GROUP BY status")
                status_counts = dict(cursor.fetchall())
                
                return {
                    'total_records': total_count,
                    'avg_price': round(avg_price, 2) if avg_price else 0,
                    'min_price': min_price or 0,
                    'max_price': max_price or 0,
                    'status_distribution': status_counts,
                    'database_file': self.output_db_path
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def convert_cian_excel_to_db(excel_path: str = "dataBD/cian_report.xlsx") -> bool:
    """–ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞ –≤ –ë–î"""
    converter = CianReportDBConverter(excel_path)
    return converter.convert_excel_to_db()

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
db_converter = CianReportDBConverter() 