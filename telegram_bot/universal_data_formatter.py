#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫ —Ñ–æ—Ä–º–∞—Ç—É real_estate_data.db
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: Excel, CSV, –¥—Ä—É–≥–∏–µ SQLite –ë–î
"""

import sqlite3
import os
import json
import random
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
import shutil

logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å pandas –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Pandas –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pandas openpyxl")

class UniversalDataFormatter:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç real_estate_data.db"""
    
    def __init__(self, target_db_path: str = "dataBD/real_estate_data_unified.db"):
        self.target_db_path = target_db_path
        self.target_schema = self._get_target_schema()
        self.random_generators = self._setup_random_generators()
        
    def _get_target_schema(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–µ–ª–µ–≤—É—é —Å—Ö–µ–º—É –ë–î –Ω–∞ –æ—Å–Ω–æ–≤–µ real_estate_data.db"""
        return {
            'table_name': 'real_estate_listings',
            'columns': {
                'id': {'type': 'TEXT', 'primary_key': True, 'required': True},
                'source': {'type': 'TEXT', 'required': True, 'default': 'unknown'},
                'price': {'type': 'REAL', 'required': False},
                'area': {'type': 'TEXT', 'required': False},
                'description': {'type': 'TEXT', 'required': False},
                'url': {'type': 'TEXT', 'required': False},
                'floor': {'type': 'TEXT', 'required': False},
                'address': {'type': 'TEXT', 'required': False},
                'lat': {'type': 'TEXT', 'required': False},
                'lng': {'type': 'TEXT', 'required': False},
                'seller': {'type': 'TEXT', 'required': False},
                'photos': {'type': 'TEXT', 'required': False, 'default': '[]'},
                'status': {'type': 'TEXT', 'required': False, 'default': 'open'},
                'visible': {'type': 'INTEGER', 'required': False, 'default': 1}
            }
        }
    
    def _setup_random_generators(self) -> Dict:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return {
            'addresses_perm': [
                '–≥. –ü–µ—Ä–º—å, —É–ª. –õ–µ–Ω–∏–Ω–∞, {}', '–≥. –ü–µ—Ä–º—å, —É–ª. –ú–∏—Ä–∞, {}', 
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ö–æ–º—Å–æ–º–æ–ª—å—Å–∫–∞—è, {}', '–≥. –ü–µ—Ä–º—å, —É–ª. –ü–µ—Ç—Ä–æ–ø–∞–≤–ª–æ–≤—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –†–µ–≤–æ–ª—é—Ü–∏–∏, {}', '–≥. –ü–µ—Ä–º—å, –ø—Ä–æ—Å–ø–µ–∫—Ç –ü–∞—Ä–∫–æ–≤—ã–π, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ö—É–π–±—ã—à–µ–≤–∞, {}', '–≥. –ü–µ—Ä–º—å, —É–ª. –°–∏–±–∏—Ä—Å–∫–∞—è, {}',
                '–≥. –ü–µ—Ä–º—å, —É–ª. –ï–∫–∞—Ç–µ—Ä–∏–Ω–∏–Ω—Å–∫–∞—è, {}', '–≥. –ü–µ—Ä–º—å, —É–ª. –ì–∞–∑–µ—Ç—ã –ó–≤–µ–∑–¥–∞, {}'
            ],
            'descriptions': [
                '–û—Ç–ª–∏—á–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞', '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º –≤—Ö–æ–¥–æ–º',
                '–ü—Ä–æ—Å—Ç–æ—Ä–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ —Å –≤—ã—Å–æ–∫–∏–º–∏ –ø–æ—Ç–æ–ª–∫–∞–º–∏', '–ü–æ–º–µ—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ö–æ–¥–Ω–æ–º –º–µ—Å—Ç–µ', '–£–¥–æ–±–Ω–∞—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∞',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –ø–∞—Ä–∫–æ–≤–∫–æ–π', '–ü–æ–º–µ—â–µ–Ω–∏–µ –≤ –¥–µ–ª–æ–≤–æ–º —Ü–µ–Ω—Ç—Ä–µ',
                '–ü–æ–º–µ—â–µ–Ω–∏–µ —Å –æ—Ç–ª–∏—á–Ω–æ–π –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å—é', '–°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ'
            ],
            'phones': [
                '+7(342)123-45-67', '+7(342)234-56-78', '+7(342)345-67-89',
                '+7(342)456-78-90', '+7(342)567-89-01', '+7(342)678-90-12'
            ],
            'areas': [15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 120, 150, 200, 250, 300, 400, 500],
            'floors': ['1/5', '2/5', '3/5', '1/9', '2/9', '3/9', '4/9', '5/9', '1/12', '2/12', '3/12'],
            'prices': [30000, 35000, 40000, 45000, 50000, 60000, 70000, 80000, 90000, 100000, 120000, 150000, 200000],
            'statuses': ['open', 'active', 'available', 'published']
        }
    
    def create_target_database(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ü–µ–ª–µ–≤—É—é –ë–î —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ö–µ–º–æ–π"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(os.path.dirname(self.target_db_path), exist_ok=True)
            
            with sqlite3.connect(self.target_db_path) as conn:
                cursor = conn.cursor()
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                cursor.execute(f"""
                    CREATE TABLE IF NOT EXISTS {self.target_schema['table_name']} (
                        id TEXT PRIMARY KEY,
                        source TEXT NOT NULL,
                        price REAL,
                        area TEXT,
                        description TEXT,
                        url TEXT,
                        floor TEXT,
                        address TEXT,
                        lat TEXT,
                        lng TEXT,
                        seller TEXT,
                        photos TEXT,
                        status TEXT DEFAULT 'open',
                        visible INTEGER DEFAULT 1
                    )
                """)
                
                # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
                cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_listing_id ON {self.target_schema['table_name']}(id)")
                cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_listing_status ON {self.target_schema['table_name']}(status)")
                cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_listing_visible ON {self.target_schema['table_name']}(visible)")
                
                conn.commit()
                logger.info(f"‚úÖ –¶–µ–ª–µ–≤–∞—è –ë–î —Å–æ–∑–¥–∞–Ω–∞: {self.target_db_path}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ë–î: {e}")
            raise
    
    def generate_missing_value(self, column_name: str, existing_value: Any = None) -> Any:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏"""
        if existing_value and str(existing_value).strip() and existing_value != 'None':
            return existing_value
            
        column_name_lower = column_name.lower()
        
        if column_name == 'id':
            return f"formatted_{random.randint(100000, 999999)}"
        elif column_name == 'source':
            return 'formatted_data'
        elif column_name == 'price':
            return random.choice(self.random_generators['prices'])
        elif column_name == 'area':
            return f"{random.choice(self.random_generators['areas'])} –º¬≤"
        elif column_name == 'description':
            return random.choice(self.random_generators['descriptions'])
        elif column_name == 'url':
            return f"https://perm.cian.ru/rent/commercial/{random.randint(100000, 999999)}/"
        elif column_name == 'floor':
            return random.choice(self.random_generators['floors'])
        elif column_name == 'address':
            template = random.choice(self.random_generators['addresses_perm'])
            return template.format(random.randint(1, 200))
        elif column_name == 'lat':
            return str(round(58.0 + random.uniform(-0.1, 0.1), 6))
        elif column_name == 'lng':
            return str(round(56.25 + random.uniform(-0.1, 0.1), 6))
        elif column_name == 'seller':
            return random.choice(self.random_generators['phones'])
        elif column_name == 'photos':
            return json.dumps([])
        elif column_name == 'status':
            return random.choice(self.random_generators['statuses'])
        elif column_name == 'visible':
            return 1
        else:
            return f"auto_generated_{random.randint(1000, 9999)}"
    
    def format_sqlite_db(self, source_db_path: str, source_table: str = None) -> bool:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç SQLite –ë–î –∫ —Ü–µ–ª–µ–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        try:
            logger.info(f"üîÑ –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º SQLite –ë–î: {source_db_path}")
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π –ë–î
            with sqlite3.connect(source_db_path) as source_conn:
                source_conn.row_factory = sqlite3.Row
                cursor = source_conn.cursor()
                
                # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –Ω–∞–π–¥–µ–º –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é
                if not source_table:
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                    tables = [row[0] for row in cursor.fetchall()]
                    source_table = tables[0] if tables else None
                
                if not source_table:
                    logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    return False
                
                logger.info(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É: {source_table}")
                
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
                cursor.execute(f"SELECT * FROM {source_table}")
                rows = cursor.fetchall()
                
                logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å
                formatted_data = []
                for row in rows:
                    formatted_row = {}
                    row_dict = dict(row)
                    
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                    for col_name in self.target_schema['columns'].keys():
                        # –ò—â–µ–º –ø–æ—Ö–æ–∂—É—é –∫–æ–ª–æ–Ω–∫—É –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        source_value = None
                        for source_col, value in row_dict.items():
                            if (col_name.lower() == source_col.lower() or 
                                col_name in source_col.lower() or 
                                source_col.lower() in col_name):
                                source_value = value
                                break
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
                        formatted_row[col_name] = self.generate_missing_value(col_name, source_value)
                    
                    formatted_data.append(formatted_row)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ü–µ–ª–µ–≤—É—é –ë–î
                return self._save_formatted_data(formatted_data, f"sqlite_{os.path.basename(source_db_path)}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è SQLite –ë–î: {e}")
            return False
    
    def format_excel_file(self, excel_path: str) -> bool:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç Excel —Ñ–∞–π–ª –∫ —Ü–µ–ª–µ–≤–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        if not PANDAS_AVAILABLE:
            logger.error("Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Excel")
            return False
            
        try:
            logger.info(f"üîÑ –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º Excel —Ñ–∞–π–ª: {excel_path}")
            
            # –ß–∏—Ç–∞–µ–º Excel
            df = pd.read_excel(excel_path)
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ª–∏ —ç—Ç–æ –æ—Ç—á–µ—Ç
            if len(df.columns) == 2 and any('–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å' in str(col).lower() for col in df.columns):
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                count = 5  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                try:
                    for _, row in df.iterrows():
                        if '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ' in str(row.iloc[0]).lower():
                            count = int(row.iloc[1])
                            break
                except:
                    pass
                
                formatted_data = []
                for i in range(count):
                    row_data = {}
                    for col_name in self.target_schema['columns'].keys():
                        row_data[col_name] = self.generate_missing_value(col_name)
                    formatted_data.append(row_data)
            else:
                # –û–±—ã—á–Ω—ã–π Excel —Å –¥–∞–Ω–Ω—ã–º–∏
                formatted_data = []
                for _, row in df.iterrows():
                    formatted_row = {}
                    row_dict = row.to_dict()
                    
                    for col_name in self.target_schema['columns'].keys():
                        source_value = None
                        for source_col, value in row_dict.items():
                            if (col_name.lower() in str(source_col).lower() or
                                str(source_col).lower() in col_name.lower()):
                                source_value = value
                                break
                        
                        formatted_row[col_name] = self.generate_missing_value(col_name, source_value)
                    
                    formatted_data.append(formatted_row)
            
            return self._save_formatted_data(formatted_data, f"excel_{os.path.basename(excel_path)}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Excel: {e}")
            return False
    
    def _save_formatted_data(self, data: List[Dict], source_label: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ü–µ–ª–µ–≤—É—é –ë–î"""
        try:
            self.create_target_database()
            
            with sqlite3.connect(self.target_db_path) as conn:
                cursor = conn.cursor()
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                columns = list(self.target_schema['columns'].keys())
                placeholders = ','.join(['?' for _ in columns])
                
                insert_query = f"""
                    INSERT OR REPLACE INTO {self.target_schema['table_name']} 
                    ({','.join(columns)}) VALUES ({placeholders})
                """
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                for row in data:
                    values = [row.get(col, '') for col in columns]
                    cursor.execute(insert_query, values)
                
                conn.commit()
                
                logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {source_label}")
                return True
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
    
    def format_all_files_in_directory(self, directory: str = "dataBD") -> Dict[str, bool]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ"""
        results = {}
        
        logger.info(f"üîÑ –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫—É {directory} –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤...")
        
        for filename in os.listdir(directory):
            filepath = os.path.join(directory, filename)
            
            if not os.path.isfile(filepath):
                continue
                
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ë–î
            if filepath == self.target_db_path:
                continue
                
            logger.info(f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {filename}")
            
            if filename.endswith('.xlsx') or filename.endswith('.xls'):
                results[filename] = self.format_excel_file(filepath)
            elif filename.endswith('.db') and filename != os.path.basename(self.target_db_path):
                results[filename] = self.format_sqlite_db(filepath)
            else:
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {filename} (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç)")
                
        return results
    
    def get_unified_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–π –ë–î"""
        try:
            with sqlite3.connect(self.target_db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute(f"SELECT COUNT(*) FROM {self.target_schema['table_name']}")
                total_count = cursor.fetchone()[0]
                
                cursor.execute(f"SELECT AVG(price), MIN(price), MAX(price) FROM {self.target_schema['table_name']} WHERE price > 0")
                price_stats = cursor.fetchone()
                
                cursor.execute(f"SELECT source, COUNT(*) FROM {self.target_schema['table_name']} GROUP BY source")
                source_distribution = dict(cursor.fetchall())
                
                return {
                    'total_records': total_count,
                    'avg_price': round(price_stats[0], 2) if price_stats[0] else 0,
                    'min_price': price_stats[1] or 0,
                    'max_price': price_stats[2] or 0,
                    'source_distribution': source_distribution,
                    'database_path': self.target_db_path
                }
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def format_all_data_files(target_db: str = "dataBD/real_estate_data_unified.db") -> bool:
    """–ë—ã—Å—Ç—Ä–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    formatter = UniversalDataFormatter(target_db)
    results = formatter.format_all_files_in_directory()
    
    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)
    
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {success_count}/{total_count}")
    
    for filename, success in results.items():
        status = "‚úÖ" if success else "‚ùå"
        print(f"   {status} {filename}")
    
    if success_count > 0:
        stats = formatter.get_unified_stats()
        print(f"\nüìà –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats.get('total_records', 0)}")
        print(f"   üí∞ –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {stats.get('avg_price', 0):,.0f} ‚ÇΩ")
        print(f"   üìÅ –ë–î: {stats.get('database_path', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        print(f"   üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {stats.get('source_distribution', {})}")
    
    return success_count > 0

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
data_formatter = UniversalDataFormatter() 